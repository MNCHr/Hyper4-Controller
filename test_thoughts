TESTING PLAN

Test Index
- t01 - L2 switch semantic equivalence test
- t02 - L3 router semantic equivalence test
- t03 - Arp proxy semantic equivalence test
- t04 - Firewall semantic equivalence test
- t05 - Chain performance test
- t06 - Feature comparison
- t07 - Modular development test
- t08 - slice impact test

Areas of Interest
- Development
- Deployment
- Management
- Maintenance

Metrics:
- latency
- bandwidth
- memory use
- packets dropped during change
- effort saved

Scenarios:
- Basic usage
  - demo function deployment + the three table ops (add, modify, delete) and
    semantic equivalence for
    - switch (topo: 3 switches in triangle, hosts off each)
    - router (topo: 1 central switch (l3 router) + 3 spoke switches (l2 switches) + hosts off each switch)
    - arp proxy
    - firewall
    - INT
    use tcpdump diff
  - demo chain via following sequence:
    - insert switch(0)
    - insert arp proxy(0)
    - append firewall
    - remove arp proxy
    - remove firewall
    - remove switch
    - traffic: how to trigger frequent ARP requests to stress / leverage the arp proxy?
               1. one host sends ping -f traffic to another in X batches
               2. observe failure until switch function inserted
               3. 

               each ping to new IP address - can we program the mininet simulation to
               fire pings automatically, or just issue 'ip -s -s neigh flush all' commands to flush arp caches each time
    - chart: latency per packet over time as events occur (infinite if dropped)
             bandwidth per 100ms as events occur
             - multiple things on timeseries, include firewall effect
    OK for scenario to be synthetic, story would be good if possible

  - show number of packets dropped, bmv2 / agilio swapping programs 'natively', vs. HP4
    - don't worry about numbers, result is more binary
    - feature comparison chart, HyPer4 vs. bmv2, PISCES, Agilio, Xilinx, others
- Modular development
  - separate programs for L2 vs L3 vs L4
  - First deploy L2
  - While packets are flowing, deploy L3
    - show latency per packet before/during/after L3 deployment
    - show bandwidth before/during/after L3 deployment
    - show that L3 has an effect:
  - forget much of above, look to implementation effort saved
  - itemize questions to resolve when manually merging
      
- Adaptive monitoring:
  - op decision to look at fourth TCP packet in BGP sessions

- Deployment: Migrate functions to areas of need in response to changing
  conditions (security, resource availability, business requirements)
  - monitoring
  - load balancers
  - translators
  - security apps: firewalls, IDS
  - just discuss broad applicability prior to adaptive monitoring e.g. motivation section
- Large scale network reconfiguration for a single tenant
  - grid infrastructure repurposed for a new tenant

Specifics:
- Need to show latency/bandwidth impact across slices

Tasks:
- read papers describing P4 switches and support for dynamic program swapping
- read P4 paper showcasing INT
- write INT.p4
- [DONE] implement Chain::replace(old_vdev_name, new_vdev_name)
  -- [DONE] make sure t_virtnet / t_egr_virtnet entries added BEFORE tset_context to
     avoid packet drops
     --- [DONE] same for insert / remove / append ops
- [LATER] implement table commands for non-loaded vdevs (just updates vdev.hp4rules)
- [DONE] implement Interpreter::table_modify
- [DONE] implement Interpreter::table_delete
- [DONE] implement resource tracking / enforcement







































Scenario One

Network consists of a forwarding switch and several hosts connected to it.

Compare instantiating an NF on the switch, appended to the forwarding function, vs. offloading the NF to a cluster.
- compare latency (expected to be better)
- compare bandwidth (expected to be worse)
- show memory usage of HP4 approach
- discuss advantage of smaller, more flexible footprint with HP4 approach vs needing a server to handle the NF and the associated connectivity (cables, forwarding infrastructure)

Need to show off the advantages of the HP4 approach
- modular design / prototyping / monitoring

Scenario Two: Adaptive Monitoring

Network consists of a forwarding switch and several hosts connected to it.

A vulnerability in a network protocol has been discovered, requiring monitoring of a field we haven't been looking at.

We have three options:
- write a custom NF and offload
- modify all hosts to monitor and report
- write a monitor P4 program and push to HP4 device


